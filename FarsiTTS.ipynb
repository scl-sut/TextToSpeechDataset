{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-E7o4_shS-2",
        "outputId": "fca3fad9-2af1-4a6d-e0fa-f864080660f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import wave"
      ],
      "metadata": {
        "id": "IJ-Hdjs2kHf8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetCombinerTTS:\n",
        "    def __init__(self, base_path):\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def read_audio_file(self, file_path):\n",
        "        \"\"\"Helper function to read audio file content.\"\"\"\n",
        "        with wave.open(file_path, 'rb') as wave_file:\n",
        "            n_frames = wave_file.getnframes()\n",
        "            frame_rate = wave_file.getframerate()\n",
        "            audio_content = wave_file.readframes(n_frames)\n",
        "        return audio_content, frame_rate\n",
        "\n",
        "    def load_Persian_TTS(self):\n",
        "        \"\"\"Load and process Persian TTS dataset.\"\"\"\n",
        "        dataset_path = os.path.join(self.base_path, 'PersianTTSDataset')\n",
        "        csv_path = os.path.join(dataset_path, 'metadata.csv')\n",
        "        wav_folder = os.path.join(dataset_path, 'wavs')\n",
        "\n",
        "        df = pd.read_csv(csv_path, header=None, names=['transcript', 'filename'], delimiter='|')\n",
        "\n",
        "        audio_contents = []\n",
        "        frame_rates = []\n",
        "        transcripts = df['transcript'].tolist()\n",
        "\n",
        "        for file_name in df['filename']:\n",
        "            file_name = str(file_name)\n",
        "            audio_path = os.path.join(wav_folder, file_name)\n",
        "            if os.path.exists(audio_path):\n",
        "                audio_content, frame_rate = self.read_audio_file(audio_path)\n",
        "                audio_contents.append(audio_content)\n",
        "                frame_rates.append(frame_rate)\n",
        "            else:\n",
        "                print(f\"File {audio_path} does not exist\")\n",
        "\n",
        "        df_persian_tts = pd.DataFrame({\n",
        "            'audio': audio_contents,\n",
        "            'frame_rate': frame_rates,\n",
        "            'transcript': transcripts\n",
        "        })\n",
        "\n",
        "        return df_persian_tts\n",
        "\n",
        "    def load_Persian_TTS_female(self):\n",
        "        \"\"\"Load and process Persian TTS female dataset.\"\"\"\n",
        "        dataset_path = os.path.join(self.base_path, 'PersianTTSDataset_female')\n",
        "        csv_path = os.path.join(dataset_path, 'metadata.csv')\n",
        "        wav_folder = os.path.join(dataset_path, 'wavs')\n",
        "\n",
        "        df = pd.read_csv(csv_path, header=None, names=['transcript', 'filename'], delimiter='|')\n",
        "\n",
        "        audio_contents = []\n",
        "        frame_rates = []\n",
        "        transcripts = df['transcript'].tolist()\n",
        "\n",
        "        for file_name in df['filename']:\n",
        "            file_name = str(file_name)\n",
        "            audio_path = os.path.join(wav_folder, file_name)\n",
        "            if os.path.exists(audio_path):\n",
        "                audio_content, frame_rate = self.read_audio_file(audio_path)\n",
        "                audio_contents.append(audio_content)\n",
        "                frame_rates.append(frame_rate)\n",
        "            else:\n",
        "                print(f\"File {audio_path} does not exist\")\n",
        "\n",
        "        df_persian_tts_female = pd.DataFrame({\n",
        "            'audio': audio_contents,\n",
        "            'frame_rate': frame_rates,\n",
        "            'transcript': transcripts\n",
        "        })\n",
        "\n",
        "        return df_persian_tts_female\n",
        "\n",
        "    def load_Persian_TTS_male(self):\n",
        "        \"\"\"Load and process Persian TTS male dataset.\"\"\"\n",
        "        dataset_path = os.path.join(self.base_path, 'PersianTTSDataset_male')\n",
        "        csv_path = os.path.join(dataset_path, 'metadata.csv')\n",
        "        wav_folder = os.path.join(dataset_path, 'wavs')\n",
        "\n",
        "        df = pd.read_csv(csv_path, header=None, names=['transcript', 'filename'], delimiter='|')\n",
        "\n",
        "        audio_contents = []\n",
        "        frame_rates = []\n",
        "        transcripts = df['transcript'].tolist()\n",
        "\n",
        "        for file_name in df['filename']:\n",
        "            file_name = str(file_name)\n",
        "            audio_path = os.path.join(wav_folder, file_name)\n",
        "            if os.path.exists(audio_path):\n",
        "                audio_content, frame_rate = self.read_audio_file(audio_path)\n",
        "                audio_contents.append(audio_content)\n",
        "                frame_rates.append(frame_rate)\n",
        "            else:\n",
        "                print(f\"File {audio_path} does not exist\")\n",
        "\n",
        "        df_persian_tts_male = pd.DataFrame({\n",
        "            'audio': audio_contents,\n",
        "            'frame_rate': frame_rates,\n",
        "            'transcript': transcripts\n",
        "        })\n",
        "        return df_persian_tts_male\n",
        "\n",
        "    def combine_datasets(self):\n",
        "        \"\"\"Combine all datasets into a single DataFrame.\"\"\"\n",
        "        df_persian_tts = self.load_Persian_TTS()\n",
        "        df_persian_tts_female = self.load_Persian_TTS_female()\n",
        "        # df_persian_tts_male = self.load_Persian_TTS_male()\n",
        "\n",
        "        # Print size of each dataset\n",
        "        print(f\"Persian TTS dataset size: {df_persian_tts.shape}\")\n",
        "        print(f\"Persian TTS female dataset size: {df_persian_tts_female.shape}\")\n",
        "        # print(f\"Persian TTS male dataset size: {df_persian_tts_male.shape}\")\n",
        "\n",
        "        # Combine all datasets\n",
        "        combined_df = pd.concat([df_persian_tts, df_persian_tts_female], ignore_index=True)\n",
        "        return combined_df\n",
        "\n",
        "    def get_combined_dataset(self):\n",
        "        \"\"\"Get the combined dataset.\"\"\"\n",
        "        return self.combine_datasets()\n",
        "\n"
      ],
      "metadata": {
        "id": "EXjkOSBBkAqt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/FarsiTTS'\n",
        "combiner = DatasetCombinerTTS(base_path)\n",
        "combined_dataset = combiner.get_combined_dataset()"
      ],
      "metadata": {
        "id": "j4a9wRxxkNej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_dataset.head())"
      ],
      "metadata": {
        "id": "rdDqkDAKnyX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Combined dataset size: {combined_dataset.shape}\")"
      ],
      "metadata": {
        "id": "FZsNHzk9vHLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PersianTTSDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio = self.dataframe.iloc[idx]['audio']\n",
        "        frame_rate = self.dataframe.iloc[idx]['frame_rate']\n",
        "        transcript = self.dataframe.iloc[idx]['transcript']\n",
        "        sample = {'audio': audio, 'frame_rate': frame_rate, 'transcript': transcript}\n",
        "        return sample"
      ],
      "metadata": {
        "id": "Q07qc4zLAguc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset = combiner.get_combined_dataset()\n",
        "persian_tts_dataset = PersianTTSDataset(combined_dataset)\n",
        "\n",
        "dataloader = DataLoader(persian_tts_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# for batch in dataloader:\n",
        "#     print(batch)\n",
        "#     break"
      ],
      "metadata": {
        "id": "QGoF0I7nAjrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3J9huOWACPsc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}